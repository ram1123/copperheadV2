{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4fbbc30-121f-48f7-9b3c-e59c106491c6",
   "metadata": {},
   "source": [
    "## CopperHead V2 tutorial\n",
    "\n",
    "This framework builds upon columnar analysis platform coffea 202x python package, using awkward arrays and dask distributed for parallelization.\n",
    "\n",
    "First we setup our config by specifying the era/year we will be doing our analysis work on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d19ab0-1f67-4a82-bb57-7aeba184795b",
   "metadata": {},
   "source": [
    "# Pre-stage\n",
    "Before we \"run\" our analysis, we prepare the list of samples that we will be performing our analysis on. This can be done by executing ```run_prestage.py``` script, specifying the chunksize by using ```--chunksize``` flag and listing the samples we would like to perform our analysis on with ```--input_string``` flag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed50e0-7df3-445a-9b43-d11076c5a964",
   "metadata": {},
   "source": [
    "The chunksize value is simple: it is an integer value of \"chunks\" of rows of data that each worker works on during parallelized workflow. \n",
    "\n",
    "Moreover, one can specify the list of data runs, MC background samples and MC signal samples for the analysis to run on by using --data, --background and --signal flag respectively. If left empty/ imcompatible (ie data 'A' in year 2017), it will just skip and move on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2dd9cc-f6b7-4f3b-bdbb-12a08f0d6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l = ['A', 'B', 'C', 'D']\n",
    "bkg_l = ['DY', 'TT',]\n",
    "sig_l = ['ggH', 'VBF']\n",
    "! python run_prestage.py --chunksize 100000 --year 2018 --cluster True --data {' '.join(data_l)} --background {' '.join(bkg_l)} --signal {' '.join(sig_l)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1baf3e-85d6-4561-b20a-0ab6cd6260be",
   "metadata": {},
   "source": [
    "If we wish to run our analysis only onto a subset of our samples in order to save time, for example, we can do so my specifying the fraction of the samples we would like to perform our analysis on with the ```--change_fraction``` flag with the accompanying floating value representing the fraction of the samples we want to work on.\n",
    "\n",
    "For example running this cell below would trim our  ```./config/fraction_processor_samples.json``` by approximately ten percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad2673-af7b-4797-9e3c-9e38abc46a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_prestage.py --change_fraction 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b9dcb-c1ed-4db8-b878-4b08b4186bc6",
   "metadata": {},
   "source": [
    "The code above will only less than a second. This will save a new config file ```./config/fraction_processor_samples.json```. Please note that we don't overwrite the original full config file ```./config/fraction_processor_samples.json```. This is so that if you would like to change your fraction value, you can do so quickly, instead of waiting a full minute to redo the whole prestage step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8cd851-aaf5-443c-8e60-f4b713e40838",
   "metadata": {},
   "source": [
    "# Running Stage 1\n",
    "\n",
    "Now we're ready to execute stage 1 of the analysis, which refers to the baseline selections we apply just before categorization of Higgs decay categories. we do this by simply running ```run_stage1.py```, though we recommend to also add ```-W ignore``` option to suppress warning flags. This operation takes the most time, ranging from 30 mins for fraction of around 0.25, all the way to hours for a full sample run. The outputs of the ```run_stage1.py``` will be saved as collection of ```.parquet``` files in the directory that's defined in the ```--save_path``` flag along with the sample name and fraction. \n",
    "\n",
    "For instance, data_A samples with fraction 0.25 with sample_path of ```/depot/cms/users/yun79/results/stage1/test/``` would be saved at ```/depot/cms/users/yun79/results/stage1/test/f0_25/data_A```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c248c1-d49a-4f99-aafe-905717d07400",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "save_path = \"/depot/cms/users/yun79/results/stage1/test/\"\n",
    "! python -W ignore run_stage1.py -y {year} --save_path {save_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f14fb3-aa01-4206-bb5c-b44940dea8fe",
   "metadata": {},
   "source": [
    "# Stage 1 Validation\n",
    "Now we validate our stage 1 outputs by plotting validation histograms. Like ```run_prestage.py``` script, we can specify the options of the plots via ```--input_string``` flag, but with different formating, but this time with mostly just boolean values: \n",
    "\n",
    "\n",
    "Ratio_{Y or N}/LogY_{Y or N}/ShowLumi_{Y or N}/Status_{work or prelim}\n",
    "\n",
    "Where we specify if we want Data/MC ratio plot in the bottom panel on with \"Y\" to mean yes and \"N\" to mean no after ```Ratio_```, plot in log scale in the y axis after ```LogY_```, show integrated luminosity value of the run after ```ShowLumi_``` and status of the plot after ```Status_```, where the option is \"work\" for \"Work in Progress\", \"prelim\" for \"Preliminary\" and empty character (\"\") for no mention of the status at all.\n",
    "\n",
    "Ie: Ratio_Y/LogY_Y/ShowLumi_N/Status_work indicates to have Data/MC ratio plot on the bottom, plot in logarithmic scale, don't show the integrated luminosity value, and have \"Work in progress\" label\n",
    "\n",
    "next is the ```--load_path``` flag, which should be identical to the path specified in ```--save_path``` flag when running the ```run_stage1.py``` script.\n",
    "\n",
    "One can also specify the path to where the validation plots will be saved by adding ```--save_path``` flag onto ```run_stage1_validation.py``` script, or just use the default path ```./validation/figs```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8122b75-efe3-4512-a278-36ca6ad480d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python run_stage1_validation.py --fraction 0.001 --input_string \"Ratio_Y/LogY_Y/ShowLumi_N/Status_work\" --load_path \"/depot/cms/users/yun79/results/stage1/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3506c3fc-ce59-4558-a715-ddbf6208a509",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_l = ['A', 'B', 'C', 'D']\n",
    "bkg_l = ['DY','TT','ST','VV','EWK']\n",
    "sig_l = ['ggH', 'VBF']\n",
    "vars2plot = ['jet', 'mu', 'dimuon', 'dijet'] \n",
    "lumi = 137.9\n",
    "status = \"Private_Work\"\n",
    "year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd72782-62c0-4ecc-a8d2-fbc219ed7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 1.0\n",
    "fraction_str = str(fraction).replace('.', '_')\n",
    "load_path = f\"/depot/cms/users/yun79/results/stage1/test_full3/{year}/f{fraction_str}\"\n",
    "! python validation_plotter_unified.py -y {year} --load_path {load_path}  -var {' '.join(vars2plot)} --data {' '.join(data_l)} --background {' '.join(bkg_l)} --signal {' '.join(sig_l)} --lumi 137.9 --status {status} --ROOT_style    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e49c2b-55e7-433d-9656-f7aa9984e7c4",
   "metadata": {},
   "source": [
    "# Stage 2\n",
    "Now we take the stage1 output for stage2: Categorization of skimmed and selected data into production mode categories. Currently, only ggH production mode is supported.\n",
    "\n",
    "Each category processes the stage1 output through their own MVAs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51588c0a-99d1-40bd-b5db-97512eebde5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stage2_load_path = \"/depot/cms/users/yun79/results/stage1/test_VBF-filter_JECon_07June2024\" # path where stage1 output is saved \n",
    "stage2_save_path = \"/work/users/yun79/stage2_output/ggH/test\" # path where stage2 output is saved \n",
    "category = \"ggH\"\n",
    "samples = [\"data\", \"signal\"] # signal here is MC signal sample (ie ggh_powheg)\n",
    "! python run_stage2.py -load {stage2_load_path} -save {stage2_save_path} --samples {' '.join(samples)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722f401d-dc87-4647-8b83-974d7e87e8ad",
   "metadata": {},
   "source": [
    "# Stage 3\n",
    "Now we do the fitting from the stage2 output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec76b1-ead3-4899-92d4-8b019525b2f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stage3_load_path = stage2_save_path\n",
    "! python run_stage3.py -load {stage3_load_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450a774-b3ce-4aec-910d-580d275e68d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root632]",
   "language": "python",
   "name": "conda-env-root632-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
