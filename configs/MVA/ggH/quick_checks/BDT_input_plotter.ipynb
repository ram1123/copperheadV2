{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb50695-99eb-4eff-a8e8-e9d7aa96b93a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dask_awkward as dak\n",
    "import awkward as ak\n",
    "from distributed import LocalCluster, Client, progress\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import mplhep as hep\n",
    "import glob\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "\n",
    "client =  Client(n_workers=15,  threads_per_worker=1, processes=True, memory_limit='8 GiB') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a7449a-0e85-4ea1-804f-ea77ea2c6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHist(events, field2plot, binning):\n",
    "    weight = ak.fill_none(events.wgt_nominal_total, value=0)\n",
    "    value = ak.fill_none(events[field2plot], value=-999)\n",
    "    # use np.isnan to filter away remaining nan values\n",
    "    nan_filter = ~(np.isnan(weight) | np.isnan(value)) # some nans are not None, apparently\n",
    "    weight = weight[nan_filter]\n",
    "    value = value[nan_filter]\n",
    "    \n",
    "    print(f\"getHist weight sum: {np.sum(weight)}\")\n",
    "    print(f\"getHist value sum: {np.sum(value)}\")\n",
    "    print(f\"getHist weight: {weight}\")\n",
    "    print(f\"getHist value: {value}\")\n",
    "    # print(f\"getHist is none weight: {ak.sum(ak.is_none(weight))}\")\n",
    "    # print(f\"getHist is none value: {ak.sum(ak.is_none(value))}\")\n",
    "    # weight = weight/ np.sum(weight) # normalize to one\n",
    "    # print(f\"np.sum(weight): {np.sum(weight)}\")\n",
    "    hist, edges = np.histogram(value, bins=binning, weights=weight)\n",
    "    print(f\"getHist hist b4 normalization: {hist}\")\n",
    "    hist = hist / np.sum(hist)\n",
    "    print(f\"np.sum(hist): {np.sum(hist)}\")\n",
    "    return hist, edges\n",
    "\n",
    "def applyGGH_cut(events):\n",
    "    btag_cut =ak.fill_none((events.nBtagLoose >= 2), value=False) | ak.fill_none((events.nBtagMedium >= 1), value=False)\n",
    "    # vbf_cut = ak.fill_none(events.vbf_cut, value=False\n",
    "    vbf_cut = (events.jj_mass > 400) & (events.jj_dEta > 2.5) \n",
    "    vbf_cut = ak.fill_none(vbf_cut, value=False)\n",
    "    region = events.h_sidebands | events.h_peak\n",
    "    # region =  events.h_peak # whether just h_peak or signal region, the plots don't change\n",
    "    ggH_filter = (\n",
    "        ~vbf_cut & \n",
    "        region &\n",
    "        ~btag_cut # btag cut is for VH and ttH categories\n",
    "    )\n",
    "    return events[ggH_filter]\n",
    "\n",
    "def getDeltaPhi(phi1,phi2):\n",
    "    phi1 = ak.ones_like(phi1, dtype=\"double\")*phi1\n",
    "    phi2 = ak.ones_like(phi2, dtype=\"double\")*phi2\n",
    "    dphi = abs(np.mod(phi1 - phi2 + np.pi, 2 * np.pi) - np.pi)\n",
    "    return dphi\n",
    "\n",
    "def computeBkgFromParquet(load_path, bkgSample_l, fields2compute):\n",
    "    zip_l = []\n",
    "    # fields2compute =  fields2compute +[\"wgt_nominal_zpt_wgt\"]\n",
    "    for sample in bkgSample_l:\n",
    "        events = dak.from_parquet(load_path+f\"/{sample}/*/*.parquet\")\n",
    "        # print(events.fields)\n",
    "        # print(events.wgt_nominal_zpt_wgt)\n",
    "        events[\"jj_dRapidity\"] = np.abs(events.jet1_rapidity - events.jet2_rapidity)\n",
    "        events[\"mmj1_dRapidity\"] = np.abs(events.jet1_rapidity - events.dimuon_rapidity)\n",
    "        events[\"mmj2_dRapidity\"] = np.abs(events.jet2_rapidity - events.dimuon_rapidity)\n",
    "        events[\"jj_dPhiV2\"] = ak.fill_none(getDeltaPhi(events.jet1_phi, events.jet2_phi), value=-1)\n",
    "        bool_filter = ak.fill_none((events.mmj1_dEta < events.mmj2_dEta), value=True)\n",
    "        events[\"mmj_min_dEtaV2\"] = ak.where(bool_filter, events.mmj1_dEta, events.mmj2_dEta)\n",
    "        bool_filter = ak.fill_none((events.mmj1_dPhi < events.mmj2_dPhi), value=True)\n",
    "        events[\"mmj_min_dPhiV2\"] = ak.where(bool_filter, events.mmj1_dPhi, events.mmj2_dPhi)\n",
    "        zip = ak.zip({field: events[field] for field in fields2compute}).compute()\n",
    "        zip_l.append(zip)\n",
    "    \n",
    "    final_zip = ak.concatenate(zip_l)\n",
    "    # zpt removal test start ------------------------\n",
    "    # final_zip[\"wgt_nominal_total\"] = final_zip.wgt_nominal_total / final_zip.wgt_nominal_zpt_wgt\n",
    "    # zpt removal test end ------------------------\n",
    "    return final_zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67323fa4-14bd-4c8e-9cae-a35ccae64249",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = {\n",
    "        \"background\": [ # for some reason, having more than dy causes things to break\n",
    "            \"dy_M-100To200\", \n",
    "            \"ttjets_dl\",\n",
    "            \"ttjets_sl\",\n",
    "            \"st_tw_top\",\n",
    "            \"st_tw_antitop\",\n",
    "            \"ww_2l2nu\",\n",
    "            \"wz_1l1nu2q\",\n",
    "            \"wz_2l2q\",\n",
    "            \"wz_3lnu\",\n",
    "            \"zz\",\n",
    "            \"ewk_lljj_mll50_mjj120\",\n",
    "        ],\n",
    "        \"signal\": [\n",
    "            \"ggh_powheg\", \n",
    "            \"vbf_powheg\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e2e9db-ff9b-40c9-854f-d863988559a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year = 2018\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/DNN_test2/{year}/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation/{year}/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_V2/{year}/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_V2/*/f1_0\"\n",
    "load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_JetIdUpdate/*/f1_0\"\n",
    "# load_path = f\"/depot/cms/users/yun79/results/stage1/BDT_inputValidation_JetIdUpdate/2018/f1_0\"\n",
    "# bkg_l = [load_path+f\"/{name}/*/*.parquet\" for name in training_samples[\"background\"]]\n",
    "# bkg_l = []\n",
    "# for bkg in training_samples[\"background\"]:\n",
    "#     bkg_l += glob.glob(load_path+f\"/{bkg}/*/*.parquet\")\n",
    "# simple from parquet doesn't work on bkg, so special care is needed\n",
    "\n",
    "# bkg_l\n",
    "# sig_l = [load_path+f\"/{name}/*/*.parquet\" for name in training_samples[\"signal\"]]\n",
    "# sig_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b9b8a5b-db56-477d-8495-d5c71af8834d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370.8627498149872\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cols_of_interest = [\n",
    "    # 'dimuon_rapidity',\n",
    "    # 'dimuon_cos_theta_cs',\n",
    "    # 'dimuon_phi_cs',\n",
    "    # 'dimuon_pt',\n",
    "    'jet1_eta',\n",
    "    'jet1_pt',\n",
    "    'jet2_pt',\n",
    "    # 'jet2_eta', # for test purpose\n",
    "    'jj_dEta',\n",
    "    'jj_dPhi',\n",
    "    'jj_dPhiV2',\n",
    "    'jj_mass',\n",
    "    # 'mmj1_dEta',\n",
    "    # 'mmj1_dPhi',\n",
    "    # 'mmj_min_dEta',\n",
    "    # 'mmj_min_dPhi',\n",
    "    # 'mmj_min_dEtaV2',\n",
    "    # 'mmj_min_dPhiV2',\n",
    "    # 'mu1_eta',\n",
    "    # 'mu1_pt_over_mass',\n",
    "    # 'mu2_eta',\n",
    "    # 'mu2_pt_over_mass',\n",
    "    # 'zeppenfeld',\n",
    "    # 'njets',\n",
    "    # \"jj_dRapidity\", # for test purpose\n",
    "    # 'mmj1_dRapidity', # for test purpose\n",
    "    # 'mmj2_dRapidity', # for test purpose\n",
    "    # 'mmj2_dEta',# for test purpose\n",
    "    # 'mmj2_dPhi',# for test purpose\n",
    "]\n",
    "additional_fields = [\n",
    "    \"wgt_nominal_total\",\n",
    "    \"h_sidebands\",\n",
    "    \"h_peak\",\n",
    "    \"vbf_cut\",\n",
    "    \"nBtagLoose\",\n",
    "    \"nBtagMedium\",\n",
    "    # \"mu1_pt\",\n",
    "    # \"mu2_pt\",\n",
    "    \"dimuon_mass\",\n",
    "    \"jet1_rapidity\",\n",
    "    \"jet2_rapidity\",\n",
    "    \"jet1_phi\",\n",
    "    \"jet2_phi\",\n",
    "]\n",
    "fields2compute = cols_of_interest +  additional_fields\n",
    "\n",
    "\n",
    "# events_bkg = dak.from_parquet(bkg_l) \n",
    "# events_bkg = ak.zip({field : events_bkg[field] for field in fields2compute}).compute()\n",
    "\n",
    "# normal from_parquet doesn't work, so using convoluted concatenating method\n",
    "\n",
    "events_bkg = computeBkgFromParquet(\n",
    "    load_path, \n",
    "    training_samples[\"background\"], \n",
    "    fields2compute,\n",
    ")\n",
    "\n",
    "\n",
    "events_bkg = applyGGH_cut(events_bkg)\n",
    "\n",
    "#calculate sig_l\n",
    "sig_l = [load_path+f\"/{name}/*/*.parquet\" for name in training_samples[\"signal\"]]\n",
    "events_sig = dak.from_parquet(sig_l)\n",
    "events_sig[\"jj_dRapidity\"] = np.abs(events_sig.jet1_rapidity - events_sig.jet2_rapidity)\n",
    "events_sig[\"mmj1_dRapidity\"] = np.abs(events_sig.jet1_rapidity - events_sig.dimuon_rapidity)\n",
    "events_sig[\"mmj2_dRapidity\"] = np.abs(events_sig.jet2_rapidity - events_sig.dimuon_rapidity)\n",
    "events_sig[\"jj_dPhiV2\"] = ak.fill_none(getDeltaPhi(events_sig.jet1_phi, events_sig.jet2_phi), value=-1)\n",
    "bool_filter = ak.fill_none((events_sig.mmj1_dEta < events_sig.mmj2_dEta), value=True)\n",
    "events_sig[\"mmj_min_dEtaV2\"] = ak.where(bool_filter, events_sig.mmj1_dEta, events_sig.mmj2_dEta)\n",
    "bool_filter = ak.fill_none((events_sig.mmj1_dPhi < events_sig.mmj2_dPhi), value=True)\n",
    "events_sig[\"mmj_min_dPhiV2\"] = ak.where(bool_filter, events_sig.mmj1_dPhi, events_sig.mmj2_dPhi)\n",
    "\n",
    "\n",
    "\n",
    "# events_sig[\"wgt_nominal_total\"].compute()\n",
    "events_sig = ak.zip({field : events_sig[field] for field in fields2compute}).compute()\n",
    "events_sig = applyGGH_cut(events_sig)\n",
    "\n",
    "print(time.time()-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bea02ca-2935-4d97-b8d6-67bb6bc2e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isnan = np.isnan(ak.to_numpy(events_bkg.wgt_nominal_total))\n",
    "# np.sum(isnan)\n",
    "# # hist_bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aef3c9f-d2f2-4a80-b2ab-b27a9bd642ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nbins = 60\n",
    "# bin_map = {\n",
    "#      \"dimuon_pt\": [0,200, nbins], \n",
    "#     \"dimuon_rapidity\" : [-2.5,2.5, nbins], \n",
    "#     \"dimuon_eta\" : [-8,8, nbins],\n",
    "# }\n",
    "with open(\"./plot_settings_gghCat_BDT_input.json\", \"r\") as file:\n",
    "    bin_map = json.load(file)\n",
    "# bin_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3ae764-41bf-4936-8cca-5ff778ddd9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getHist weight sum: 881.5309439082096\n",
      "getHist value sum: -971341.2513500757\n",
      "getHist weight: [0.000379, 0.000224, 0.000261, 0.000312, ..., 2.23e-05, 2.45e-05, 3.51e-05]\n",
      "getHist value: [-1, -1, -1, -1, -1, -1, -1, -1, ..., -1, 2.95, -1, -1, 0.453, -1, -1, 0.521]\n",
      "getHist hist b4 normalization: [2.52, 2.54, 2.68, 2.65, 2.78, 2.8, ..., 3.19, 3.17, 3.3, 3.34, 3.51, 3.54]\n",
      "np.sum(hist): 1.0\n",
      "getHist weight sum: 1737178.0372940407\n",
      "getHist value sum: -20602466.672882587\n",
      "getHist weight: [0.0293, 0.0325, 0.0273, 0.0258, -0.0255, ..., 0.0103, 0.0119, 0.0113, 0.0143]\n",
      "getHist value: [-1, -1, -1, -1, -1, -1, -1, -1, -1, ..., 2.33, -1, -1, -1, 1.49, 1.8, -1, 2.28]\n",
      "getHist hist b4 normalization: [2.52e+03, 2.6e+03, 2.57e+03, 2.66e+03, ..., 7.31e+03, 7.59e+03, 7.93e+03]\n",
      "np.sum(hist): 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year = \"Run2\"\n",
    "# for field in cols_of_interest:\n",
    "for field in ([\"jj_dPhiV2\"]):\n",
    "    binning = np.linspace(*bin_map[field][\"binning_linspace\"])\n",
    "    xmin = bin_map[field][\"binning_linspace\"][0]\n",
    "    xmax = bin_map[field][\"binning_linspace\"][1]\n",
    "    hist_sig, edges = getHist(events_sig, field, binning)\n",
    "    # raise ValueError\n",
    "    hist_bkg, edges = getHist(events_bkg, field, binning)\n",
    "    fig, ax_main = plt.subplots()\n",
    "    # plt.stairs(hist_sig,edges=edges,label=\"signal\", color=\"blue\")\n",
    "    # plt.stairs(hist_bkg,edges=edges,label=\"background\", color=\"red\")\n",
    "    hep.histplot(\n",
    "        hist_sig, \n",
    "        bins=binning, \n",
    "        stack=False, \n",
    "        histtype='step', \n",
    "        color='blue', \n",
    "        label='signal', \n",
    "        ax=ax_main,\n",
    "    )\n",
    "    # print(f\"hist_bkg: {hist_bkg}\")\n",
    "    hep.histplot(\n",
    "        hist_bkg, \n",
    "        bins=binning, \n",
    "        stack=False, \n",
    "        histtype='step', \n",
    "        color='red', \n",
    "        label='background', \n",
    "        ax=ax_main,\n",
    "    )\n",
    "    ax_main.set_xlabel(bin_map[field][\"xlabel\"])\n",
    "    ax_main.set_ylabel(\"A.U.\")\n",
    "    if bin_map[field][\"logscale\"]:\n",
    "        plt.yscale('log')  # Set y-axis to log scale\n",
    "        plt.ylim(1e-3, 1)\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "    CenterOfMass = 13\n",
    "    # lumi = 59.97 # 2018 lumi value\n",
    "    lumi = 137.9 # Run2 value\n",
    "    hep.cms.label(data=True, loc=0, label=\"Private Work\", com=CenterOfMass, ax=ax_main, lumi=lumi)\n",
    "    plt.savefig(f\"plots/BDT_input{year}_{field}\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dcdad5-391a-4147-9827-1b876ea26b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.sum(ak.is_none(events_bkg.jj_dPhiV2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5b45a-5787-4522-8d64-52632ec8999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ak.Array([2.0], dtype=\"double\")\n",
    "ak.types.NumpyType.copy(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b3e350-62e6-475d-82c2-2f9772cd12ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root632]",
   "language": "python",
   "name": "conda-env-root632-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
